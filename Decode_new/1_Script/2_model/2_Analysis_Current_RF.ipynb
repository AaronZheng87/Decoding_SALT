{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(y, y_pred):\n",
    "    score = roc_auc_score(y, y_pred, multi_class=\"ovr\")\n",
    "    return score\n",
    "\n",
    "my_scores = make_scorer(score_func=score_func, greater_is_better=True, needs_proba=True, needs_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../2_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noref = pd.read_csv(\"/Users/zhengyuanrui/Decoding_SALT/Decode_new/2_Data/df_no_ref.csv\")\n",
    "df_selfref = pd.read_csv(\"/Users/zhengyuanrui/Decoding_SALT/Decode_new/2_Data/df_self_ref.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selfref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_noref, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_selfref, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norefc = df_noref.iloc[:, 8:11].values\n",
    "X_selfrefc = df_selfref.iloc[:, 9:12].values\n",
    "\n",
    "y_noref = df_noref[\"label\"].values\n",
    "y_selfref = df_selfref[\"label\"].values\n",
    "\n",
    "norefcolc = df_noref.iloc[:, 8:11].columns\n",
    "selfrefcolc = df_selfref.iloc[:, 9:12].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_selfref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_no = df_noref[\"Subject\"].values\n",
    "groups_self = df_selfref[\"Subject\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_within_task(X, y, group, source):\n",
    "    feature_importance = []\n",
    "    df_result = dict(subID=[], score=[], source=[], target=[])# source拟合的，target预测的condition\n",
    "    for train, test in logo.split(X, y, groups=group):\n",
    "        test_sub = np.unique(group[test])[0]\n",
    "        df_result[\"subID\"].append(test_sub)\n",
    "        \n",
    "        rf = make_pipeline(MinMaxScaler(), \n",
    "                       RandomForestClassifier(n_estimators=500, bootstrap=True, \n",
    "                                              random_state=123, class_weight=\"balanced\", \n",
    "                                              criterion = \"entropy\", max_samples=0.9, n_jobs=-1))\n",
    "        \n",
    "        model = rf.fit(X=X[train], y=y[train])\n",
    "        im = permutation_importance(model, X[test], y[test], scoring=my_scores, n_repeats=20, n_jobs=-1, random_state=123)\n",
    "        feature_importance.append(im['importances_mean'])\n",
    "        y_pred = model.predict_proba(X[test])\n",
    "        score = roc_auc_score(y[test], y_pred, multi_class='ovr')\n",
    "\n",
    "        df_result['score'].append(score)\n",
    "        df_result['source'].append(source)\n",
    "        df_result['target'].append(source)\n",
    "\n",
    "    return pd.DataFrame(df_result), feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cross_task(X_source, y_source, X_target, y_target, target_group, source_name, target_name):\n",
    "    df_result = dict(subID=[], score=[], source=[], target=[])# source拟合的，target预测的condition\n",
    "    feature_importance = []\n",
    "    rf = make_pipeline(MinMaxScaler(), \n",
    "                       RandomForestClassifier(n_estimators=500, bootstrap=True, \n",
    "                                              random_state=123, class_weight=\"balanced\", \n",
    "                                              criterion = \"entropy\", max_samples=0.9, n_jobs=-1))\n",
    "    model = rf.fit(X=X_source, y=y_source)\n",
    "\n",
    "\n",
    "    for sub in np.unique(target_group):\n",
    "        idx_sub = target_group == sub\n",
    "        feature_sub = X_target[idx_sub]\n",
    "        label_sub = y_target[idx_sub]\n",
    "\n",
    "        im = permutation_importance(model, feature_sub, label_sub, scoring=my_scores, n_repeats=20, n_jobs=-1, random_state=123)\n",
    "        feature_importance.append(im['importances_mean'])\n",
    "\n",
    "        y_pred = model.predict_proba(feature_sub)\n",
    "        score = roc_auc_score(label_sub, y_pred, multi_class=\"ovr\")\n",
    "\n",
    "        df_result['subID'].append(sub)\n",
    "        df_result[\"score\"].append(score)\n",
    "        df_result[\"source\"].append(source_name)\n",
    "        df_result[\"target\"].append(target_name)\n",
    "\n",
    "\n",
    "    return pd.DataFrame(df_result) , feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_noc_rf,  im_noc_rf= rf_within_task(X = X_norefc, y = y_noref, group = groups_no, source=\"No_Ref\")\n",
    "score_selfc_rf,  im_selfc_rf= rf_within_task(X = X_selfrefc, y = y_selfref, group = groups_self, source=\"Self_Ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No ref to self ref\n",
    "df_cross1c_rf, im_cross1c_rf = rf_cross_task(X_source=X_norefc, y_source=y_noref, X_target=X_selfrefc, y_target=y_selfref, target_group=groups_self, source_name=\"No_Ref\", target_name=\"Self_Ref\")\n",
    "#self to no ref\n",
    "df_cross2c_rf, im_cross2c_rf = rf_cross_task(X_source=X_selfrefc, y_source=y_selfref, X_target=X_norefc, y_target=y_noref, target_group=groups_no, source_name=\"Self_Ref\", target_name=\"No_Ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
